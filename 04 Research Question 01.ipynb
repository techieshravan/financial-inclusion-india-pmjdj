{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3197722d-228f-4aad-be0d-1f07b4d6d374",
   "metadata": {},
   "source": [
    "### RESEARCH QUESTION 1: DETERMINANTS OF HIGH PMJDY ACCOUNT OPERATIONALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d1aec-9b53-4e32-a68e-eba04153bcc2",
   "metadata": {},
   "source": [
    "**Objective**: Which state-level characteristics predict whether a state achieves greater than 75% operative account rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57e1b2f-cf6c-41e4-8019-2598850d3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                           roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09340ae0-3138-441e-a8d2-17092b8d8479",
   "metadata": {},
   "source": [
    "### STEP 1: DATA LOADING AND EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555b54bf-3771-4d2a-8134-ea7d823087ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: DATA LOADING AND EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "Dataset Sizes:\n",
      "  Training set: 28 states, 55 features\n",
      "  Test set: 8 states, 55 features\n",
      "  Full dataset: 36 states\n",
      "\n",
      "Target Distribution (High_Operative_Flag):\n",
      "  Training - Class 0 (≤75%): 9 states\n",
      "  Training - Class 1 (>75%): 19 states\n",
      "  Training - Positive ratio: 67.9%\n",
      "  Test - Class 0 (≤75%): 2 states\n",
      "  Test - Class 1 (>75%): 6 states\n",
      "  Test - Positive ratio: 75.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: DATA LOADING AND EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load preprocessed datasets\n",
    "train_data = pd.read_csv('ml_train_High_Operative_Flag.csv')\n",
    "test_data = pd.read_csv('ml_test_High_Operative_Flag.csv')\n",
    "full_data = pd.read_csv('ml_preprocessed_full.csv')\n",
    "\n",
    "print(f\"\\nDataset Sizes:\")\n",
    "print(f\"  Training set: {train_data.shape[0]} states, {train_data.shape[1]} features\")\n",
    "print(f\"  Test set: {test_data.shape[0]} states, {test_data.shape[1]} features\")\n",
    "print(f\"  Full dataset: {full_data.shape[0]} states\")\n",
    "\n",
    "# Target distribution\n",
    "print(f\"\\nTarget Distribution (High_Operative_Flag):\")\n",
    "print(f\"  Training - Class 0 (≤75%): {(train_data['High_Operative_Flag']==0).sum()} states\")\n",
    "print(f\"  Training - Class 1 (>75%): {(train_data['High_Operative_Flag']==1).sum()} states\")\n",
    "print(f\"  Training - Positive ratio: {train_data['High_Operative_Flag'].mean():.1%}\")\n",
    "print(f\"  Test - Class 0 (≤75%): {(test_data['High_Operative_Flag']==0).sum()} states\")\n",
    "print(f\"  Test - Class 1 (>75%): {(test_data['High_Operative_Flag']==1).sum()} states\")\n",
    "print(f\"  Test - Positive ratio: {test_data['High_Operative_Flag'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d289dd-5d28-4881-ac7c-c1af47cde45e",
   "metadata": {},
   "source": [
    "### STEP 2: FEATURE SELECTION (Based on Methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f138d0-05db-488d-87cc-deab6332f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: FEATURE SELECTION\n",
      "================================================================================\n",
      "\n",
      "Available features: 18\n",
      "Missing features: []\n",
      "\n",
      "Final feature set: 18 features\n",
      "\n",
      "Feature Categories:\n",
      "  - Rural/Urban metrics: ['Rural_Urban_Ratio', 'Rural_Percent']\n",
      "  - Growth metrics: ['CAGR_2020_25', 'Growth_2024_25', 'Growth_Operative_Interaction']\n",
      "  - Operative metrics: ['Jan25_Op_Rate', 'Operative_Mean', 'Operative_Trend']\n",
      "  - Regional indicators: ['Region_North', 'Region_South', 'Region_East']\n",
      "\n",
      "Training set: X=(28, 18), y=(28,)\n",
      "Test set: X=(8, 18), y=(8,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: FEATURE SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select key features as per methodology\n",
    "key_features = [\n",
    "    # Primary predictors from methodology\n",
    "    'Rural_Urban_Ratio',  # Rural-Urban Distribution Ratio (if not present, calculate)\n",
    "    'RuPay_Penetration',   # RuPay Card Penetration Rate\n",
    "    'Avg_Balance_Rs',      # Average Account Balance\n",
    "    'Account_Density_Per_Lakh',  # Account Density per Lakh Population\n",
    "    'CAGR_2020_25',        # Historical Growth Momentum\n",
    "    \n",
    "    # Additional relevant features from preprocessing\n",
    "    'Jan25_Op_Rate',       # Current operative rate\n",
    "    'Rural_Percent',       # Rural dominance\n",
    "    'Growth_2024_25',      # Recent growth\n",
    "    'Operative_Mean',      # Mean operative rate over time\n",
    "    'Operative_Trend',     # Trend in operative rates\n",
    "    \n",
    "    # Engineered features\n",
    "    'Growth_Operative_Interaction',  # Growth-Operative interaction\n",
    "    'Account_Density_Squared',       # Non-linear relationship\n",
    "    \n",
    "    # Regional dummies\n",
    "    'Region_North', 'Region_South', 'Region_East', \n",
    "    'Region_West', 'Region_Northeast', 'Region_Central'\n",
    "]\n",
    "\n",
    "# Check which features are available\n",
    "available_features = [f for f in key_features if f in train_data.columns]\n",
    "missing_features = [f for f in key_features if f not in train_data.columns]\n",
    "\n",
    "print(f\"\\nAvailable features: {len(available_features)}\")\n",
    "print(f\"Missing features: {missing_features}\")\n",
    "\n",
    "# If Rural_Urban_Ratio is missing, calculate it\n",
    "if 'Rural_Urban_Ratio' not in train_data.columns and 'Rural_Beneficiaries' in train_data.columns:\n",
    "    if 'Urban_Beneficiaries' in train_data.columns:\n",
    "        train_data['Rural_Urban_Ratio'] = train_data['Rural_Beneficiaries'] / (train_data['Urban_Beneficiaries'] + 1)\n",
    "        test_data['Rural_Urban_Ratio'] = test_data['Rural_Beneficiaries'] / (test_data['Urban_Beneficiaries'] + 1)\n",
    "        available_features.append('Rural_Urban_Ratio')\n",
    "        print(\"  ✓ Calculated Rural_Urban_Ratio\")\n",
    "\n",
    "# Update feature list\n",
    "features_to_use = [f for f in available_features if f in train_data.columns]\n",
    "\n",
    "print(f\"\\nFinal feature set: {len(features_to_use)} features\")\n",
    "print(\"\\nFeature Categories:\")\n",
    "print(f\"  - Rural/Urban metrics: {[f for f in features_to_use if 'Rural' in f or 'Urban' in f][:3]}\")\n",
    "print(f\"  - Growth metrics: {[f for f in features_to_use if 'Growth' in f or 'CAGR' in f][:3]}\")\n",
    "print(f\"  - Operative metrics: {[f for f in features_to_use if 'Operative' in f or 'Op_Rate' in f][:3]}\")\n",
    "print(f\"  - Regional indicators: {[f for f in features_to_use if 'Region' in f][:3]}\")\n",
    "\n",
    "# Prepare data\n",
    "X_train = train_data[features_to_use]\n",
    "y_train = train_data['High_Operative_Flag']\n",
    "X_test = test_data[features_to_use]\n",
    "y_test = test_data['High_Operative_Flag']\n",
    "\n",
    "print(f\"\\nTraining set: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1cc94-e90c-4614-8ccf-b411633bf24e",
   "metadata": {},
   "source": [
    "### STEP 3: BOOTSTRAP-ENHANCED LOGISTIC REGRESSION (PRIMARY MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e027e7c-f5fe-474b-8ebf-db672ee9d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: BOOTSTRAP-ENHANCED LOGISTIC REGRESSION\n",
      "================================================================================\n",
      "\n",
      "Running 1000 bootstrap iterations...\n",
      "  Completed 100 iterations...\n",
      "  Completed 200 iterations...\n",
      "  Completed 300 iterations...\n",
      "  Completed 400 iterations...\n",
      "  Completed 500 iterations...\n",
      "  Completed 600 iterations...\n",
      "  Completed 700 iterations...\n",
      "  Completed 800 iterations...\n",
      "  Completed 900 iterations...\n",
      "  Completed 1000 iterations...\n",
      "\n",
      "Bootstrap Logistic Regression Results:\n",
      "  Out-of-bag accuracy: 0.847\n",
      "  Average prediction confidence: 0.908\n",
      "\n",
      "Test Set Performance:\n",
      "  Accuracy: 0.875\n",
      "  Precision: 0.857\n",
      "  Recall: 1.000\n",
      "  F1-Score: 0.923\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: BOOTSTRAP-ENHANCED LOGISTIC REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def bootstrap_logistic_regression(X_train, y_train, X_test, n_iterations=1000):\n",
    "    \"\"\"\n",
    "    Implement bootstrap-enhanced logistic regression with Firth's penalty approximation\n",
    "    \"\"\"\n",
    "    n_samples = len(X_train)\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # Store results from each bootstrap iteration\n",
    "    predictions = []\n",
    "    coefficients = []\n",
    "    accuracies = []\n",
    "    \n",
    "    print(f\"\\nRunning {n_iterations} bootstrap iterations...\")\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Bootstrap sample\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        X_boot = X_train.iloc[indices]\n",
    "        y_boot = y_train.iloc[indices]\n",
    "        \n",
    "        # Fit logistic regression with regularization (approximates Firth's penalty)\n",
    "        lr = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=i)\n",
    "        lr.fit(X_boot, y_boot)\n",
    "        \n",
    "        # Store predictions and coefficients\n",
    "        pred = lr.predict(X_test)\n",
    "        predictions.append(pred)\n",
    "        coefficients.append(lr.coef_[0])\n",
    "        \n",
    "        # Calculate out-of-bag accuracy if possible\n",
    "        oob_indices = list(set(range(n_samples)) - set(indices))\n",
    "        if len(oob_indices) > 0:\n",
    "            X_oob = X_train.iloc[oob_indices]\n",
    "            y_oob = y_train.iloc[oob_indices]\n",
    "            oob_pred = lr.predict(X_oob)\n",
    "            oob_acc = accuracy_score(y_oob, oob_pred)\n",
    "            accuracies.append(oob_acc)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Completed {i + 1} iterations...\")\n",
    "    \n",
    "    # Aggregate predictions using majority voting\n",
    "    predictions_array = np.array(predictions)\n",
    "    final_predictions = np.apply_along_axis(\n",
    "        lambda x: np.bincount(x).argmax(), 0, predictions_array\n",
    "    )\n",
    "    \n",
    "    # Calculate confidence (proportion of votes for winning class)\n",
    "    confidence = np.mean(predictions_array == final_predictions[np.newaxis, :], axis=0)\n",
    "    \n",
    "    # Calculate coefficient statistics\n",
    "    coefficients_array = np.array(coefficients)\n",
    "    coef_mean = np.mean(coefficients_array, axis=0)\n",
    "    coef_std = np.std(coefficients_array, axis=0)\n",
    "    \n",
    "    # BCa confidence intervals (simplified version)\n",
    "    coef_ci_lower = np.percentile(coefficients_array, 2.5, axis=0)\n",
    "    coef_ci_upper = np.percentile(coefficients_array, 97.5, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'predictions': final_predictions,\n",
    "        'confidence': confidence,\n",
    "        'coefficients_mean': coef_mean,\n",
    "        'coefficients_std': coef_std,\n",
    "        'coefficients_ci': (coef_ci_lower, coef_ci_upper),\n",
    "        'oob_accuracy': np.mean(accuracies) if accuracies else None\n",
    "    }\n",
    "\n",
    "# Run bootstrap logistic regression\n",
    "bootstrap_results = bootstrap_logistic_regression(X_train, y_train, X_test, n_iterations=1000)\n",
    "\n",
    "print(\"\\nBootstrap Logistic Regression Results:\")\n",
    "print(f\"  Out-of-bag accuracy: {bootstrap_results['oob_accuracy']:.3f}\")\n",
    "print(f\"  Average prediction confidence: {np.mean(bootstrap_results['confidence']):.3f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_bootstrap = bootstrap_results['predictions']\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_pred_bootstrap):.3f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_bootstrap):.3f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_pred_bootstrap):.3f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_test, y_pred_bootstrap):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a67994-87e0-4a2b-b95e-767f7f45ee87",
   "metadata": {},
   "source": [
    "### STEP 4: SECONDARY MODELS FOR VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e061d3-d48a-4d19-9d7e-6fa3a079af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: SECONDARY MODELS FOR VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.875\n",
      "  Precision: 0.857\n",
      "  Recall: 1.000\n",
      "  F1-Score: 0.923\n",
      "  AUC-ROC: 0.667\n",
      "\n",
      "Random Forest:\n",
      "  Accuracy: 0.875\n",
      "  Precision: 0.857\n",
      "  Recall: 1.000\n",
      "  F1-Score: 0.923\n",
      "  AUC-ROC: 1.000\n",
      "\n",
      "SVM (RBF):\n",
      "  Accuracy: 0.750\n",
      "  Precision: 0.750\n",
      "  Recall: 1.000\n",
      "  F1-Score: 0.857\n",
      "  AUC-ROC: 0.750\n",
      "\n",
      "Gradient Boosting:\n",
      "  Accuracy: 1.000\n",
      "  Precision: 1.000\n",
      "  Recall: 1.000\n",
      "  F1-Score: 1.000\n",
      "  AUC-ROC: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: SECONDARY MODELS FOR VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # AUC-ROC if probabilities available\n",
    "    if y_pred_proba is not None:\n",
    "        auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        auc_roc = None\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "    if auc_roc:\n",
    "        print(f\"  AUC-ROC: {auc_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d9761-7ba8-4815-9d74-b8ed0886ec89",
   "metadata": {},
   "source": [
    "### STEP 5: LEAVE-ONE-OUT CROSS-VALIDATION (LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d5b979-40e6-4157-969e-a837504808cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5: LEAVE-ONE-OUT CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Performing LOOCV on 36 states...\n",
      "\n",
      "LOOCV Results (Logistic Regression):\n",
      "  Mean Accuracy: 0.889\n",
      "  Std Deviation: 0.314\n",
      "  Min Accuracy: 0.000\n",
      "  Max Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: LEAVE-ONE-OUT CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine train and test for full LOOCV\n",
    "X_full = pd.concat([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "print(f\"\\nPerforming LOOCV on {len(X_full)} states...\")\n",
    "\n",
    "# LOOCV for Logistic Regression\n",
    "loo = LeaveOneOut()\n",
    "lr_model = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Calculate LOOCV scores\n",
    "loocv_scores = cross_val_score(lr_model, X_full, y_full, cv=loo, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nLOOCV Results (Logistic Regression):\")\n",
    "print(f\"  Mean Accuracy: {np.mean(loocv_scores):.3f}\")\n",
    "print(f\"  Std Deviation: {np.std(loocv_scores):.3f}\")\n",
    "print(f\"  Min Accuracy: {np.min(loocv_scores):.3f}\")\n",
    "print(f\"  Max Accuracy: {np.max(loocv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535acc5-1bf9-42f0-9538-bb367d0c7433",
   "metadata": {},
   "source": [
    "### STEP 6: FEATURE IMPORTANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2bcccd9-655d-4033-84d2-f785c3e0fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 6: FEATURE IMPORTANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Top 10 Most Important Features (Random Forest):\n",
      "  6. Jan25_Op_Rate: 0.3520\n",
      "  9. Operative_Mean: 0.0893\n",
      "  5. CAGR_2020_25: 0.0743\n",
      "  1. Rural_Urban_Ratio: 0.0696\n",
      "  11. Growth_Operative_Interaction: 0.0691\n",
      "  10. Operative_Trend: 0.0652\n",
      "  8. Growth_2024_25: 0.0627\n",
      "  12. Account_Density_Squared: 0.0569\n",
      "  7. Rural_Percent: 0.0398\n",
      "  3. Avg_Balance_Rs: 0.0335\n",
      "\n",
      "Top Features by Odds Ratios (Logistic Regression):\n",
      "Features with Odds Ratio > 1 (positive association):\n",
      "  Operative_Mean: OR=2.775\n",
      "  Operative_Trend: OR=2.326\n",
      "  Growth_2024_25: OR=1.779\n",
      "  CAGR_2020_25: OR=1.747\n",
      "  Region_West: OR=1.692\n",
      "\n",
      "Features with Odds Ratio < 1 (negative association):\n",
      "  Account_Density_Per_Lakh: OR=0.983\n",
      "  Avg_Balance_Rs: OR=0.961\n",
      "  RuPay_Penetration: OR=0.944\n",
      "  Region_East: OR=0.855\n",
      "  Region_North: OR=0.423\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get feature importance from Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features_to_use,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (Random Forest):\")\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# Calculate odds ratios from logistic regression coefficients\n",
    "lr_model_final = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42)\n",
    "lr_model_final.fit(X_train, y_train)\n",
    "\n",
    "odds_ratios = np.exp(lr_model_final.coef_[0])\n",
    "feature_odds = pd.DataFrame({\n",
    "    'feature': features_to_use,\n",
    "    'coefficient': lr_model_final.coef_[0],\n",
    "    'odds_ratio': odds_ratios\n",
    "}).sort_values('odds_ratio', ascending=False)\n",
    "\n",
    "print(\"\\nTop Features by Odds Ratios (Logistic Regression):\")\n",
    "print(\"Features with Odds Ratio > 1 (positive association):\")\n",
    "positive_features = feature_odds[feature_odds['odds_ratio'] > 1].head(5)\n",
    "for i, row in positive_features.iterrows():\n",
    "    print(f\"  {row['feature']}: OR={row['odds_ratio']:.3f}\")\n",
    "\n",
    "print(\"\\nFeatures with Odds Ratio < 1 (negative association):\")\n",
    "negative_features = feature_odds[feature_odds['odds_ratio'] < 1].head(5)\n",
    "for i, row in negative_features.iterrows():\n",
    "    print(f\"  {row['feature']}: OR={row['odds_ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c545e-1ec6-4523-abea-31e6a423c676",
   "metadata": {},
   "source": [
    "### STEP 7: FINAL SUMMARY AND RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93e43dd-c40c-4191-9c55-28fefaad81ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n",
      "\n",
      "1. MODEL PERFORMANCE COMPARISON:\n",
      "----------------------------------------\n",
      "                    accuracy precision recall  f1_score   auc_roc\n",
      "Logistic Regression    0.875  0.857143    1.0  0.923077  0.666667\n",
      "Random Forest          0.875  0.857143    1.0  0.923077       1.0\n",
      "SVM (RBF)               0.75      0.75    1.0  0.857143      0.75\n",
      "Gradient Boosting        1.0       1.0    1.0       1.0       1.0\n",
      "\n",
      "Best performing model (by F1-Score): Gradient Boosting\n",
      "\n",
      "2. KEY PREDICTORS OF HIGH OPERATIONALIZATION (>75%):\n",
      "----------------------------------------\n",
      "High-impact features (OR > 2.0):\n",
      "  • Operative_Mean: OR=2.78\n",
      "  • Operative_Trend: OR=2.33\n",
      "\n",
      "3. STATISTICAL VALIDATION:\n",
      "----------------------------------------\n",
      "  Bootstrap OOB Accuracy: 0.847\n",
      "  LOOCV Mean Accuracy: 0.889\n",
      "  Test Set Best F1-Score: 1.000\n",
      "\n",
      "4. POLICY RECOMMENDATIONS:\n",
      "----------------------------------------\n",
      "  • Historical growth momentum predicts future operationalization\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. MODEL PERFORMANCE COMPARISON:\")\n",
    "print(\"-\" * 40)\n",
    "performance_df = pd.DataFrame(results).T\n",
    "print(performance_df[['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']].round(3))\n",
    "\n",
    "best_model = performance_df['f1_score'].idxmax()\n",
    "print(f\"\\nBest performing model (by F1-Score): {best_model}\")\n",
    "\n",
    "print(\"\\n2. KEY PREDICTORS OF HIGH OPERATIONALIZATION (>75%):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Identify top 3 predictors with odds ratios > 2.0\n",
    "high_impact_features = feature_odds[feature_odds['odds_ratio'] > 2.0].head(3)\n",
    "if len(high_impact_features) > 0:\n",
    "    print(\"High-impact features (OR > 2.0):\")\n",
    "    for i, row in high_impact_features.iterrows():\n",
    "        print(f\"  • {row['feature']}: OR={row['odds_ratio']:.2f}\")\n",
    "else:\n",
    "    print(\"Top 3 features by odds ratio:\")\n",
    "    for i, row in feature_odds.head(3).iterrows():\n",
    "        print(f\"  • {row['feature']}: OR={row['odds_ratio']:.2f}\")\n",
    "\n",
    "print(\"\\n3. STATISTICAL VALIDATION:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Bootstrap OOB Accuracy: {bootstrap_results['oob_accuracy']:.3f}\")\n",
    "print(f\"  LOOCV Mean Accuracy: {np.mean(loocv_scores):.3f}\")\n",
    "print(f\"  Test Set Best F1-Score: {performance_df['f1_score'].max():.3f}\")\n",
    "\n",
    "print(\"\\n4. POLICY RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Based on top features, provide recommendations\n",
    "if 'Jan25_Op_Rate' in feature_odds.head(3)['feature'].values:\n",
    "    print(\"  • States should focus on improving current operative rates\")\n",
    "if 'Rural_Percent' in feature_odds.head(3)['feature'].values or 'Rural_Urban_Ratio' in feature_odds.head(3)['feature'].values:\n",
    "    print(\"  • Rural-urban composition significantly impacts operationalization\")\n",
    "if 'RuPay_Penetration' in feature_odds.head(3)['feature'].values:\n",
    "    print(\"  • RuPay card distribution is crucial for account activation\")\n",
    "if 'Account_Density_Per_Lakh' in feature_odds.head(3)['feature'].values:\n",
    "    print(\"  • Account penetration density matters for operational success\")\n",
    "if any('Growth' in f for f in feature_odds.head(3)['feature'].values):\n",
    "    print(\"  • Historical growth momentum predicts future operationalization\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25393d7e-babd-4153-b659-522548f3dc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
